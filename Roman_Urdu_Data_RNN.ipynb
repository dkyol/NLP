{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Goal: To train a sentiment classifier on a corpus of provided documents in order to maximize accuracy. There is special interest in being able to accurately detect negative sentiment. The training data includes documents from a wide variety of sources, not merely social media, and some of it may be inconsistently labeled. Describe the business outcomes including how data limitations impact your results and how these limitations could be addressed in a larger project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Roman Urdu Data Set Data Set contains about 20,000 rows and two columns.  The columns contain the text and sentiment -- negative, positve and neutral.  The text field contains punctuation, missing fields, capitilization, words form other languages and some non-text characters. \n",
    "\n",
    "There are several identical entries in the text column which have different label sentiments.  Based on the information given, that the social media company wants to identify negative sentiment, it is assumed that this is not a multi-label classification problem.  That any given phrase or sentence will only would either be positive, neutral or negative, and not some combination of the classes.\n",
    "\n",
    "Additionally, a large number of inconsistently labeled entries might lessen the ability to delineate the feature space. The negatively labeled rows make up about a quarter of the dataset. In an attempt to identify inconsistently labeled text, the text was converted to lower case in order to complete a comparison evalutaion besed on the value of each entry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20229, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_file = pd.read_csv('Roman Urdu DataSet.csv',\n",
    "                names = ['text', 'sentiment', 'unamed'], dtype = {'text': str, 'sentiment': str})\n",
    "#size of dataset \n",
    "flat_file.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kya bt hai,</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wah je wah</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are wha kaya bat hai</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment unamed\n",
       "0  Sai kha ya her kisi kay bus ki bat nhi hai lak...  Positive    NaN\n",
       "1                                          sahi bt h  Positive    NaN\n",
       "2                                        Kya bt hai,  Positive    NaN\n",
       "3                                         Wah je wah  Positive    NaN\n",
       "4                               Are wha kaya bat hai  Positive    NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     8929\n",
       "Positive    6013\n",
       "Negative    5286\n",
       "Neative        1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_file.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert all text to lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_file.iloc[:,0] = flat_file.text.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compare Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four looping functions are used to compare the text, and to identify **inconsistently labeled** data:\n",
    "    \n",
    "    1. similar_text\n",
    "    \n",
    "    2. Index_duplicates\n",
    "    \n",
    "    3. dupe_drop\n",
    "    \n",
    "    4. drop_text\n",
    "    \n",
    "Nested for loops are used to search through the rows to find duplicates.  This is an expensive operation, especially for larger datasets.  The  '==' comparison is used in case any of the text with the same value do not also point to the same object.  The approach is first to find identical row entries, to use that collection to search through the dataset to find the indices of dulpicative entries, to evaluate if duplicative entries have two or more labels and if so do to drop identical entries with two or more different classes from the analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nested loops to cycle through the data to find duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_text(list_values):\n",
    "    '''Extract subset from text column with same value '''\n",
    "    text_list = []\n",
    "\n",
    "    for i in range(len(list_values)):\n",
    "        count = 0\n",
    "        \n",
    "        for j in range(len(list_values)):\n",
    "            \n",
    "            if list_values[i] == list_values[j]:\n",
    "                count+=1\n",
    "                \n",
    "        if (count > 2):\n",
    "            \n",
    "            text_list.append(list_values[i])\n",
    "    \n",
    "    return set(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create list of indices where duplicates exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_duplicates(duplicate, dupe_df):\n",
    "    \n",
    "    '''return indices of duplicates '''\n",
    "    \n",
    "    dupe_index = []\n",
    "    \n",
    "    for i in range(len(dupe_df.text)):\n",
    "        \n",
    "        if dupe_df.text[i] == duplicate:\n",
    "            \n",
    "            dupe_index.append(i)\n",
    "            \n",
    "    return dupe_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for more than one label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dupe_drop(dupe_list, dupe_df):\n",
    "    \n",
    "    '''return if text if text has more than one label''' \n",
    "    \n",
    "    df = dupe_df.iloc[dupe_list]\n",
    "    \n",
    "    if len(set(df.sentiment))!=1:\n",
    "        \n",
    "        return df.text[dupe_list[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of non-text data that has also been inconsistently labeled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>:)</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>:)</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10594</th>\n",
       "      <td>:)</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text sentiment unamed\n",
       "7791    :)   Neutral    NaN\n",
       "8181    :)   Neutral    NaN\n",
       "10594   :)  Negative    NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_ind = index_duplicates(':)', flat_file)\n",
    "df = flat_file.loc[dp_ind]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop only duplicates with two or more labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_text(dupeList, df):\n",
    "    \n",
    "    '''text and index of text to drop from corpus dataset'''\n",
    "    \n",
    "    totalText = []\n",
    "    totalIndices = []\n",
    "    \n",
    "    #list of duplicates \n",
    "    dupeList = list(dupeList)\n",
    "    \n",
    "    for dupe in (dupeList):\n",
    "        \n",
    "        #get indices of duplicates \n",
    "        dpList = index_duplicates(dupe, df)\n",
    "        \n",
    "        #return instances of duplicates with more than one label \n",
    "        dupe_name = dupe_drop(dpList, df)\n",
    "        \n",
    "        if dupe_name is not None:\n",
    "            totalText.append(dupe_name)\n",
    "            \n",
    "            for i in range(len(dpList)):\n",
    "            \n",
    "                totalIndices.append(dpList[i])\n",
    "        \n",
    "    return totalText, totalIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is list of test with different sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hahahah',\n",
       " 'haha',\n",
       " 'wah',\n",
       " 'lol',\n",
       " 'bilkul',\n",
       " 'jee ye to he',\n",
       " 'hahahha',\n",
       " 'bilkul sahi',\n",
       " ':)',\n",
       " 'hahahaha',\n",
       " 'acha',\n",
       " 'shadi ka na hona, jadu ka toor, bimariyan, shoar ko apna bana ,jumla masil ka rohani haal mojod ha mayoos afrad rabta kren masla hal ho jaen ga inshallah.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find duplicative text \n",
    "duplicates = similar_text(list(flat_file.text))\n",
    "\n",
    "#identify text to drop\n",
    "drop_these, dropIndices = drop_text(duplicates, flat_file)\n",
    "\n",
    "drop_these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing steps are aimed at reducing all non-character format including punctutation.  The unamed axis is also dropped.  All blank text, and series of blank text is reduced and then dropped. One label misspelled label is amended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df):\n",
    "    \n",
    "    '''Pre-process flat file removing puntuation, dropping blank rows and labeling'''\n",
    "\n",
    "    # drop inconsistently labeled rows\n",
    "    corpus = df.drop(dropIndices, axis = 0)\n",
    "\n",
    "    #drop unamed column\n",
    "    corpus = corpus.drop(labels = 'unamed', axis = 1)\n",
    "\n",
    "    #remove anything that is not space or character\n",
    "    corpus.text = corpus.text.str.replace('[^\\s\\w]', ' ')\n",
    "    # remove digits, newline and _ char\n",
    "    corpus.text = corpus.text.str.replace('[\\d\\n_]', ' ')\n",
    "    \n",
    "    #replace two or more spaces with one space\n",
    "    corpus.text = corpus.text.str.replace('[ ]{2,}', ' ')\n",
    "\n",
    "    #drop blank sentiment \n",
    "    single_s = corpus.text.loc[corpus.text == ' '].index[:]\n",
    "    \n",
    "    #make list\n",
    "    t_space = list(single_s) \n",
    "\n",
    "    #drop rows without blank text \n",
    "    corpus = corpus.drop(t_space, axis = 0)\n",
    "    \n",
    "    # replace blank cells with nans\n",
    "    corpus.text.replace([''], np.nan, inplace=True)\n",
    "    \n",
    "    # drop nan columns\n",
    "    corpus.dropna(axis = 0, inplace = True)\n",
    "    \n",
    "    # re-label sentiment \n",
    "    corpus.sentiment = ['Negative' if x == 'Neative' else x for x in corpus.sentiment]\n",
    "\n",
    "    corpus.sentiment = [1 if x == 'Negative' else 0 for x in corpus.sentiment]\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resulting cleaner dataset, re-indexed and relabled** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resulting data post processing  \n",
    "corpus = pre_processing(flat_file)\n",
    "\n",
    "corpus = corpus.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of rows removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_file.shape[0] - corpus.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels have been reassigned combining the postive and neutral classes which are indicated with zeros, and negative class is indicated by 1's.  This change from a multi-classification problem to a binary one seems to align with the business objective to identify negative sentiment, and is thought to improve the accuracy of identifying negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    14685\n",
      "1     5285\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sai kha ya her kisi kay bus ki bat nhi hai lak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sahi bt h</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kya bt hai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wah je wah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are wha kaya bat hai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  sai kha ya her kisi kay bus ki bat nhi hai lak...          0\n",
       "1                                          sahi bt h          0\n",
       "2                                        kya bt hai           0\n",
       "3                                         wah je wah          0\n",
       "4                               are wha kaya bat hai          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#description of resulting set of sentiment  \n",
    "print(corpus.sentiment.value_counts())\n",
    "\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encode text field with vocab dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Count Vectorizer to get unique words from text column \n",
    "text_list = list(corpus.text)\n",
    "\n",
    "vector = CountVectorizer(analyzer='word')\n",
    "\n",
    "vocab_table =  vector.fit_transform(text_list)\n",
    "\n",
    "# resulting vocabulary \n",
    "vocab = vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The CountVecorizer class is used to find the unique vocabulary of the text field**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than **31,000** unique words/characters used in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocabulary Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoded dictionary assigning each word to a number  \n",
    "\n",
    "vocab_dict = {}\n",
    "\n",
    "for i, word in enumerate(vocab, start = 1):\n",
    "    \n",
    "    vocab_dict.update({word: i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode Text** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_corpus = []\n",
    "characters  = []\n",
    "\n",
    "# encode code each sentence in text column using the vocab_dict\n",
    "for i in range(len(text_list)):\n",
    "    \n",
    "    encode_sentence = []\n",
    "\n",
    "    for word in text_list[i].split():\n",
    "        \n",
    "        try:\n",
    "    \n",
    "            encode_sentence.append(vocab_dict[word])\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            # characters not found in vocab_dict\n",
    "            characters.append(word)\n",
    "    \n",
    "    encode_corpus.append(encode_sentence)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row has been encoded using the vocabulary dictionary: **vocab_dict** <br>\n",
    "\n",
    "The sample entry below at row index 15305 contains five different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18264, 1243, 23439, 8832, 1378]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_corpus[15305]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the encoding process there were several instances where characters were not found in the vocabulary dictionary and therefore were not able to be encoded.  **There were 29 different characters that were not contained in the dictionary.**  These letters were not added to the dictionary.  In a TF-IDF approach these items would have likely been \"Stop Words\" and removed.  It is also possible that these letters form were part of contraction in which case theoritically a lemmatized version of the word still remains in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exceptions - not encoded \n",
    "len(set(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Standardize word vector length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count frequency of sequence length found in text \n",
    "freq = []\n",
    "for line in encode_corpus:\n",
    "    m = len(line)\n",
    "    freq.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows depicts the number of words in a row and the x axis indicates that there are about 20,000 rows in the dataset.<br>\n",
    "\n",
    "The median number of words in row is: **9**\n",
    "\n",
    "The average number of words in a row is about: **13**\n",
    "\n",
    "The max number of words in row is: **288**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff18dbacf60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#frequency distribution of length of text   \n",
    "pd.DataFrame(freq).plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding the length of Vector Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_input(list_of_list, length_int):\n",
    "    \n",
    "    '''pad text input with zeros to provide standard input for model'''\n",
    "\n",
    "    pad_corpus = []\n",
    "    \n",
    "    seq_length = []\n",
    "    \n",
    "    drop_indices  = []\n",
    "\n",
    "    for i in range(len(list_of_list)):\n",
    "        \n",
    "        # padding word vectors \n",
    "        \n",
    "        if (len(list_of_list[i]) <= length_int) and (len(list_of_list[i]) > 0):\n",
    "            \n",
    "            # adding zeros \n",
    "            zeros = list(np.zeros(length_int - len(list_of_list[i]), dtype = int))\n",
    "\n",
    "            total = zeros + list_of_list[i]\n",
    "            \n",
    "            pad_corpus.append(total)\n",
    "            \n",
    "            seq_length.append(len(list_of_list[i]))          \n",
    "        \n",
    "        #truncate \n",
    "        \n",
    "        elif len(list_of_list[i]) > length_int:\n",
    "\n",
    "            pad = list_of_list[i][:length_int]\n",
    "\n",
    "            pad_corpus.append(pad)\n",
    "            \n",
    "            seq_length.append(len(list_of_list[i]))    \n",
    "        \n",
    "        # error checking \n",
    "        else:\n",
    "            \n",
    "            drop_indices.append(i)\n",
    "                 \n",
    "    return pad_corpus, seq_length, drop_indices      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pad_input function (above) counts the number of words in a row and either truncates the text or add zeros (from left to right to ensure that each row of input is of equal length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 40\n",
    "\n",
    "#pad_text - contains all the encoded equal length vectors \n",
    "\n",
    "pad_corpus, seq, drop_indices = pad_input(encode_corpus, vector_length)\n",
    "\n",
    "# labels \n",
    "y = corpus.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Checking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the padding process, additional issues were discovered.  The variable **drop_indices** contains the additional list of rows that will be dropped.  Many of these instances are of empty list that may have been created during the encoding process when the set of 29 characters were not encoded.  These instances that may require further discussion to best understand how to code a more comprehensive pre-processing step that catches more edge cases and improves data quality.<br>\n",
    "\n",
    "This further reduces the number of rows by additional **35** rows. That brings the total number of dropped rows to **294** rows or about **1.5%** of the data.<br>\n",
    "\n",
    "It also means that the labels will have also have to be amended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_clean(y, list_index):\n",
    "    \n",
    "    # remove labels aligned to bad data\n",
    "    \n",
    "    y_new = []\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        \n",
    "        if i not in list_index:\n",
    "            \n",
    "            y_new.append(y[i])\n",
    "        \n",
    "    return y_new "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The features and labels used in the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y_clean(y, drop_indices)\n",
    "\n",
    "features = pad_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Subsections of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_base, y_train, y_base = train_test_split(features[:len(features)-1], \n",
    "                                                    labels[:len(labels)-1], test_size=.20006, random_state=305)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_base, y_base, test_size=.5, random_state=305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model is trained on about 80% percent of the data, leaving 10% for each of the validation and testing sections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 15946 X samples and 15946 y samples\n",
      "Validation set contains 1994 X samples and 1994 y samples\n",
      "Test set contains 1994 X samples and 1994 y samples\n"
     ]
    }
   ],
   "source": [
    "print('Training set contains {} X samples and {} y samples'.format(len(X_train),len(y_train)))\n",
    "print('Validation set contains {} X samples and {} y samples'.format(len(X_val),len(y_val)))\n",
    "print('Test set contains {} X samples and {} y samples'.format(len(X_test),len(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating TensorDatasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(torch.from_numpy(np.asarray(X_train)), torch.from_numpy(np.asarray(y_train)))\n",
    "val = TensorDataset(torch.from_numpy(np.asarray(X_val)), torch.from_numpy(np.asarray(y_val)))\n",
    "test = TensorDataset(torch.from_numpy(np.asarray(X_test)), torch.from_numpy(np.asarray(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataLoaders Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size is for this model is 2.  The batch size was driven by the desire do not arbitraily drop data.  The generators require that batch size is a multiple of each data subsection --training, validation, test.  However, the smaller batch size reduces the memory used at any given time facilitating larger models, this at the cost of higher fluctuations of performance metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size \n",
    "size = 2\n",
    "\n",
    "# create data load generators \n",
    "\n",
    "train_load = DataLoader(train, shuffle = True, batch_size=size)\n",
    "\n",
    "val_load = DataLoader(val, shuffle = True, batch_size=size)\n",
    "\n",
    "test_load = DataLoader(test, shuffle = True, batch_size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model implemented here is a RNN that uses a stacked LSTM cell that passes state in the forward direction.  The model consists of an embedding layer (dimensions vocabulary x embed_dim), dropout layers to reduce overfitting and improve the chances that the model will generalize well on new data.  The model also consists of a dense, linear layer and passes the final output through a sigmoid activation layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class romanModel(nn.Module):\n",
    "    \n",
    "    \"RNN model to classify sentiment\"\n",
    "    \n",
    "    def __init__(self, vocab, output, embed_dim, hidden_dim, size_var, n_layers, drop=.3):\n",
    "        \n",
    "        super(romanModel, self).__init__()\n",
    "        \n",
    "        self.output = output\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = size_var\n",
    "        \n",
    "        # initialize embedding layer\n",
    "        self.embedding = nn.Embedding(vocab, embed_dim)\n",
    "        \n",
    "        # initialize lstm layer \n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first = True, dropout = drop)\n",
    "        \n",
    "        # initialize dropout layer \n",
    "        self.dp_layer = nn.Dropout(drop)\n",
    "        \n",
    "        # initalilize fully connected linear layer\n",
    "        self.fully_connected = nn.Linear(hidden_dim, output)\n",
    "        \n",
    "        # sigmoid activation \n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # first dim of input \n",
    "        self.batch_size = x.size(0)\n",
    "        \n",
    "        #convert tensor to long type\n",
    "        x = x.long()\n",
    "        \n",
    "        #feed input into embedding layer\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        # -output: (batch, seq length, hidden_dim) - hidden - 2x (num layers, batch, hidden_dims)\n",
    "        out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        #apply dropout layer \n",
    "        out = self.dp_layer(out)\n",
    "        \n",
    "        # linear layer (batch, seq length, 1)\n",
    "        out = self.fully_connected(out)\n",
    "        \n",
    "        #sigmoid layer (batch, seq length, 1) 0-1\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        #separate by batch (batch, embed_dim) \n",
    "        out = out.view(self.batch_size, -1)\n",
    "        \n",
    "        # take last value from each batch (batch) \n",
    "        out = out[:, -1]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def hidden_state(self):\n",
    "        \n",
    "        '''size hidden and cell state tensors'''\n",
    "        \n",
    "        weight = next(self.parameters())\n",
    "        \n",
    "        if(gpu):   \n",
    "            # sized hidden state placed on Gpu\n",
    "            hidden = (weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_().cuda(), \n",
    "                      weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_().cuda())\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            hidden = (weight.new(self.n_layers, self.batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters were listed below.  of the listed parameters vector_length (the length of the input), the embed dimension and the hidden dimension were of most interest.  In general, increasing either vector length or the hidden parameters has not resulted in signifcant better model performance.<br>\n",
    "\n",
    "Increasing vector length also increases the number of placeholder (padded) non-useful inputs into the dataset, but more work could be done to design more comprehensive training jobs to have a better understanding as to how each parameter impacts the results of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture \n",
    "n_layers = 2\n",
    "output_var = 1\n",
    "embed_dim = 600\n",
    "hidden_dim = 256\n",
    "size_var = size\n",
    "vocab_length = len(vocab) + 1\n",
    "\n",
    "# training parameters \n",
    "epoch = 2\n",
    "clip = 5\n",
    "\n",
    "model = romanModel(vocab_length, output_var, embed_dim, hidden_dim, size_var, n_layers)\n",
    "\n",
    "# model parameters \n",
    "learning_rate = .001\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The latest and best validation model are saved during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best model - avg validation loss\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar') \n",
    "        \n",
    "        print('Model Saved.........................................' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model trains with relatively few passes through the data.  The number of epochs taken is reduced to capture the best model before increased overfitting begins to occur.<br>\n",
    "\n",
    "In order to train the larger models and explore more permutations of parameters the best model is not picked up to produce the results.  This was done to reduce the need load more data into memory, however the number of epochs was estimated so that the best model would be used to infer the evaluation results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU has started...\n",
      "Epoch... 1\n",
      "Epoch progress... 0.25\n",
      "Epoch progress... 0.5\n",
      "Epoch progress... 0.75\n",
      "Epoch progress... 1.0\n",
      "Model Saved.........................................\n",
      "Training loss.... 1.010295851805343\n",
      "Validation loss... 0.5142550337032127\n",
      "Epoch... 2\n",
      "Epoch progress... 0.25\n",
      "Epoch progress... 0.5\n",
      "Epoch progress... 0.75\n",
      "Epoch progress... 1.0\n",
      "Training loss.... 0.31080721849402176\n",
      "Validation loss... 0.5309591039396596\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "if (gpu):\n",
    "    model.cuda()\n",
    "    print('Training on GPU has started...')\n",
    "\n",
    "count_row = 0\n",
    "best_val = 1\n",
    "model.train()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print('Epoch...', i+1)\n",
    "    # initialize hidden input \n",
    "    hid = model.hidden_state()\n",
    "    # cycle training data \n",
    "    validation_loss = []\n",
    "    train_loss = 0\n",
    "    \n",
    "    for features, labels in (train_load):\n",
    "        \n",
    "        #move to gpu\n",
    "        if (gpu):\n",
    "            \n",
    "            features = features.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        count_row +=1\n",
    "        \n",
    "        # zero gradient \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # input features and hidden state, model outputs projection and hidden state \n",
    "        output, hid = model(features, hid)\n",
    "        \n",
    "        hid = (hid[0].detach(), hid[0].detach())\n",
    "        \n",
    "        # binary cross entropy loss\n",
    "        loss = loss_function(output, labels.float())\n",
    "        \n",
    "        # calculate the gradient \n",
    "        loss.backward()\n",
    "        \n",
    "        # limit size of gradient \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        #update with gradient \n",
    "        optimizer.step()\n",
    "        \n",
    "        # interval set to quarters \n",
    "        interval = int((len(X_train)/size)/4)\n",
    "        \n",
    "        if count_row % interval == 0: \n",
    "            \n",
    "            print('Epoch progress...', round(((count_row/(len(X_train)/size))-i), 2))           \n",
    "            \n",
    "            # initialize hidden state\n",
    "            hid_val = model.hidden_state()\n",
    "            \n",
    "            #set model to evaluation mode\n",
    "            model.eval()\n",
    "            \n",
    "            #cycle through validation data \n",
    "            for features_val, labels_val in val_load:\n",
    "                \n",
    "                if (gpu):\n",
    "                    \n",
    "                    features_val = features_val.cuda()\n",
    "                    labels_val = labels_val.cuda()                \n",
    "\n",
    "                output_val, hid_val = model(features_val, hid_val)\n",
    "                \n",
    "                # validation loss metirc \n",
    "                loss_val = loss_function(output_val, labels_val.float())\n",
    "                \n",
    "                #record validation metrics per batch\n",
    "                validation_loss.append(loss_val.item())\n",
    "\n",
    "            # reset model to train mode\n",
    "            model.train()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # validation metric \n",
    "    current_val = sum(validation_loss)/len(validation_loss)\n",
    "\n",
    "    #compare model metrics\n",
    "    is_best = current_val < best_val\n",
    "\n",
    "    best_val = min(current_val, best_val)\n",
    "\n",
    "    #model state \n",
    "    best_state = {\n",
    "\n",
    "        'epoch': i+1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'opt_dict' : optimizer.state_dict(), \n",
    "    }\n",
    "\n",
    "    #checkpoint model \n",
    "    save_checkpoint(best_state, is_best, filename='checkpoint.pth.tar')  \n",
    "     \n",
    "    #print training metrics     \n",
    "    print('Training loss....', train_loss/(count_row/size))\n",
    "    print('Validation loss...', sum(validation_loss)/len(validation_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size initial hidden states\n",
    "#hid_test = model.hidden_state()\n",
    "\n",
    "#empty lists\n",
    "total_pred = []\n",
    "total_labels = []\n",
    "\n",
    "# set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# initialize hidden state\n",
    "hid_test = model.hidden_state()\n",
    "    \n",
    "for features_test, labels_test in test_load:\n",
    "\n",
    "    if (gpu):\n",
    "\n",
    "        features_test = features_test.cuda()\n",
    "        labels_test = labels_test.cuda()\n",
    "        model = model.cuda()\n",
    "\n",
    "\n",
    "    #get predictions \n",
    "    pred, hid_test = model(features_test, hid_test)\n",
    "    \n",
    "    #rounded prediction tensor \n",
    "    pred = torch.round(pred)\n",
    "\n",
    "    #predictions and labels \n",
    "    total_pred += list(pred.detach().cpu().numpy())\n",
    "    total_labels += list(labels_test.detach().cpu().numpy())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1464\n",
      "           1       0.68      0.48      0.56       530\n",
      "\n",
      "    accuracy                           0.80      1994\n",
      "   macro avg       0.75      0.70      0.71      1994\n",
      "weighted avg       0.79      0.80      0.79      1994\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Postive/Neutral'), Text(0, 1.5, 'Negative')]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "\n",
    "print(classification_report(total_labels, total_pred))\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(confusion_matrix(total_labels, total_pred), annot=True, fmt='g', ax = ax) \n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "\n",
    "ax.xaxis.set_ticklabels(['Postive/Neutral', 'Negative'])\n",
    "ax.yaxis.set_ticklabels(['Postive/Neutral', 'Negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy of this model, with the given parameters is about 80%** <br>\n",
    "\n",
    "There are more false positives than false negatives so the model wrongly predicts negative sentiment more often than it fails to indicate negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary business objective was to identify negative sentiment in the data optimizing for accuracy. This model could potentially establish the baseline for evaluating improved models.  In general, would result in models with more predictive power. In general, more accurate models should result from more data being available for training, tuning an evalutaion.\n",
    "\n",
    "With more data, and the resources to conduct training more data could result in word embedded layers specfic to this application. An embedded layer containing the vector word representations of the words in this dataset would likely improve the model. \n",
    "\n",
    "With more data, one could sample it in a manner that may yield better results.  It has been mentioned, that inputs of this data have variable length, and that including vectors of longer length results in adding uneseful data.  Additional data would make it feasible to conduct analysis to better understand how the model can be optimized for certain lengths of input.  \n",
    "\n",
    "More data would result in a more balanced dataset, which would facilitate more rigorous testing and potentially eliminate the need to resample the data. This model was found to be more effective at identifying positve/neutral data, which represents the majority of the sample. Sampling could be used to build a more balanced dataset, but at the risk of causing other issues resulting from either reusing samples or further reducing the size of the dataset.  \n",
    "\n",
    "The test data set on which the evaluation metrics are based contain only about 2,000 records.  With more data, one would not only be more confident in the performance metrics, but also that some bias is not having some unforseen impact on how the results should be interpreted.  For example, it could be possible that this data set was taken during a time period, or during an event the skews what would ordinarily indicate a given sentiment.\n",
    "\n",
    "More data would also inform how to select a modeling approach.  With more data, it is possible to learn that less complex, more inexpensive models could be implemented while still acheiveing a given accuracy threshold, or also that additional complexity is justified.  Support Vector Machine models preformed well on this limited dataset, but it is difficult to complete a full business case analysis of that approach compared to a deep learning approach with Attention that would likley perform better, at higher cost and complexity.  The amount of data redefines the scope of the challenge and as a result working with the amount of data expected when at scale would provide the best insight appraoch any analytic challenge.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
